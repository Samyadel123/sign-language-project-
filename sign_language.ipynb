{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM17sc1eAf6AJE0oM9ze+a3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samyadel123/sign-language-project-/blob/main/sign_language.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "upload you kaggle api"
      ],
      "metadata": {
        "id": "X1Sr_l1fX46V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "ql-3KKKmS0Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "4EkJenO6UWTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "downloding the dataset"
      ],
      "metadata": {
        "id": "fr21YXZkX-jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download risangbaskoro/wlasl-processed"
      ],
      "metadata": {
        "id": "EUnVk5ooWbrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/wlasl-processed.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OCpWwAR6WjP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loud_json(file_name:str):\n",
        "  import json\n",
        "  with open(file_name) as f:\n",
        "    data = json.load(f)\n",
        "  return data"
      ],
      "metadata": {
        "id": "l6Ld1wQVRq3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(\"/content/WLASL_v0.3.json\",\"r\") as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "hDkQdEAzSLi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code to see the vido"
      ],
      "metadata": {
        "id": "n9jYgf8vdVdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "# Import the Colab-specific display function and utility for clearing output\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Set the path to your video file\n",
        "video_path = \"/content/videos/00335.mp4\"\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video file at {video_path}\")\n",
        "else:\n",
        "    # Get the original FPS for a smoother display (optional but recommended)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    if fps > 0:\n",
        "        delay = 1 / fps\n",
        "    else:\n",
        "        delay = 0.033 # Default to ~30 FPS if not found\n",
        "\n",
        "    # Loop through the video frames\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            # If the frame was not read successfully, break the loop\n",
        "            break\n",
        "\n",
        "        # 1. Display the frame using the Colab-specific function\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        # 2. Clear the previous output cell to simulate video\n",
        "        # The 'wait=True' ensures a smooth transition\n",
        "        #clear_output(wait=True)\n",
        "\n",
        "        # Optional: Add a small sleep to regulate frame rate (improves playback quality)\n",
        "        time.sleep(delay)\n",
        "\n",
        "    # Release the VideoCapture object\n",
        "    cap.release()\n",
        "    print(\"Video playback finished.\")\n",
        "\n",
        "# Note: cv2.destroyAllWindows() is NOT needed in Colab."
      ],
      "metadata": {
        "id": "vYtYRE7kXuMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(frame)"
      ],
      "metadata": {
        "id": "crAXNknNoN3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AssemblyAI-Examples/mediapipe-python.git\n",
        "!pip install mediapipe\n",
        "!pip install PyQt5\n",
        "!pip install ipython==7.32.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ek1BT2ApgkAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "def mediapip_dedection(fram,model):\n",
        "  fram = cv2.cvtColor(fram,cv2.COLOR_BGR2RGB) # color conversion for mediapipe\n",
        "  fram.flags.writeable = False\n",
        "  results = model.process(fram)\n",
        "  fram.flags.writeable = True\n",
        "  fram = cv2.cvtColor(fram,cv2.COLOR_RGB2BGR)\n",
        "  return fram,results\n",
        "\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n"
      ],
      "metadata": {
        "id": "lpZVLJ_4dYrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_landmarks(image, results):\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
        "    return image"
      ],
      "metadata": {
        "id": "MvJmAm6lnYwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_stayled_landmarks(image,results):\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                              mp_drawing.DrawingSpec(color=(80,22,10),thickness=1,circle_radius=1),\n",
        "                              mp_drawing.DrawingSpec(color=(80,44,121),thickness=1,circle_radius=1)\n",
        "                              )\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                              mp_drawing.DrawingSpec(color=(121,22,76),thickness=1,circle_radius=1),\n",
        "                              mp_drawing.DrawingSpec(color=(121,44,250),thickness=1,circle_radius=1)\n",
        "                              )\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                              mp_drawing.DrawingSpec(color=(245,117,66),thickness=1,circle_radius=1),\n",
        "                              mp_drawing.DrawingSpec(color=(245,66,230),thickness=1,circle_radius=1)\n",
        "                              )\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
        "                              mp_drawing.DrawingSpec(color=(80,110,10),thickness=1,circle_radius=1)\n",
        "                              mp_drawing.DrawingSpec(color=(80,256,121),thickness=1,circle_radius=1)\n",
        "                            )\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "id": "BuQZnqnsqrNa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
        "  cap = cv2.VideoCapture(\"/content/videos/00335.mp4\")\n",
        "  while cap.isOpened():\n",
        "    ret,frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    # make dedection\n",
        "    image, result = mediapip_dedection(frame,holistic)\n",
        "\n",
        "    # draw landmarks\n",
        "    image = draw_stayled_landmarks(image,result)\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "      break\n",
        "  cap.release()\n",
        "  cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "xiHKqt1MkbzU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}